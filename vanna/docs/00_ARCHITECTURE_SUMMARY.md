# Vanna ì „ì²´ ì•„í‚¤í…ì²˜ ìš”ì•½

## ğŸ“š í”„ë¡œì íŠ¸ ê°œìš”
- **í”„ë¡œì íŠ¸**: Vanna
- **ì €ì¥ì†Œ**: https://github.com/vanna-ai/vanna
- **ëª©ì **: **ìì—°ì–´ë¥¼ SQLë¡œ ë³€í™˜í•˜ëŠ” RAG ê¸°ë°˜ Text-to-SQL í”„ë ˆì„ì›Œí¬**
- **íŠ¹ì§•**: Vector Storeì™€ LLMì„ ììœ ë¡­ê²Œ ì¡°í•© ê°€ëŠ¥í•œ í”ŒëŸ¬ê·¸ì¸ ì•„í‚¤í…ì²˜

---

## ğŸ¯ í•µì‹¬ ë¬¸ì œì™€ í•´ê²°

### ë¬¸ì œ 1: Text-to-SQLì˜ ê·¼ë³¸ì  í•œê³„
**Before**: Fine-tuningìœ¼ë¡œ SQL ìƒì„±
- âŒ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ë³€ê²½ ì‹œ ì¬í•™ìŠµ í•„ìš”
- âŒ í•™ìŠµ ë¹„ìš© ë†’ìŒ (ì‹œê°„ + ë¹„ìš©)
- âŒ ìƒˆë¡œìš´ í…Œì´ë¸” ì¶”ê°€ ì‹œ ì¦‰ì‹œ ë°˜ì˜ ë¶ˆê°€ëŠ¥

**After**: RAG (Retrieval-Augmented Generation)
- âœ… ìŠ¤í‚¤ë§ˆ ë³€ê²½ ì¦‰ì‹œ ë°˜ì˜ (Vector Storeì— ì¶”ê°€ë§Œ)
- âœ… Fine-tuning ë¶ˆí•„ìš”
- âœ… Few-shot learning (ê³¼ê±° SQL ì˜ˆì‹œ í™œìš©)

**í•µì‹¬ ì•„ì´ë””ì–´**:
```
ì§ˆë¬¸: "ì§€ë‚œë‹¬ ë§¤ì¶œ ìƒìœ„ 10ê°œ ìƒí’ˆì€?"
  â†“
1. Vector Search: ìœ ì‚¬í•œ ê³¼ê±° ì§ˆë¬¸ + SQL ê²€ìƒ‰
2. Retrieval: ê´€ë ¨ í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ (DDL) ê²€ìƒ‰
3. Augmentation: LLM Prompt êµ¬ì„± (Few-shot + DDL)
4. Generation: LLMì´ SQL ìƒì„±
  â†“
SELECT * FROM products ORDER BY revenue DESC LIMIT 10
```

---

### ë¬¸ì œ 2: Vector Storeì™€ LLM ì¢…ì†ì„±
**Before**: íŠ¹ì • Vector Store + íŠ¹ì • LLMì— ê°•ê²°í•©
```python
class VannaOpenAI:
    def __init__(self):
        self.chroma = ChromaDB()
        self.llm = OpenAI()
```
- âŒ ë‹¤ë¥¸ Vector Store ì‚¬ìš© ë¶ˆê°€ëŠ¥
- âŒ ë‹¤ë¥¸ LLM ì‚¬ìš© ë¶ˆê°€ëŠ¥
- âŒ ìƒˆ êµ¬í˜„ ì¶”ê°€ ì‹œ ì „ì²´ ì½”ë“œ ìˆ˜ì •

**After**: Mixin íŒ¨í„´
```python
# Base class with abstract methods
class VannaBase(ABC):
    @abstractmethod
    def add_question_sql(self, question, sql): pass  # Vector Store

    @abstractmethod
    def submit_prompt(self, prompt): pass  # LLM

# ì‚¬ìš©ìê°€ ì¡°í•©
class MyVanna(ChromaDB_VectorStore, OpenAI_Chat):
    pass

# ë˜ëŠ”
class MyVanna(Pinecone_VectorStore, Anthropic_Chat):
    pass
```
- âœ… Vector Storeì™€ LLM ë…ë¦½ì 
- âœ… ìƒˆ êµ¬í˜„ ì¶”ê°€ ì‹œ base.py ìˆ˜ì • ë¶ˆí•„ìš”
- âœ… ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì¡°í•© ì„ íƒ

---

### ë¬¸ì œ 3: ë°ì´í„°ë² ì´ìŠ¤ ë…ë¦½ì„±
**Before**: DBë§ˆë‹¤ ë³„ë„ í´ë˜ìŠ¤
```python
class PostgresVanna: ...
class MySQLVanna: ...
class SnowflakeVanna: ...
# 11ê°œ DB â†’ 11ê°œ í´ë˜ìŠ¤ â†’ ì½”ë“œ ì¤‘ë³µ
```

**After**: Dynamic Function Binding (Closure íŒ¨í„´)
```python
def connect_to_postgres(self, host, dbname, user, password):
    def connect_to_db():
        return psycopg2.connect(host=host, dbname=dbname, ...)

    def run_sql_postgres(sql: str) -> pd.DataFrame:
        conn = connect_to_db()  # Closure!
        cs = conn.cursor()
        cs.execute(sql)
        return pd.DataFrame(...)

    # ëŸ°íƒ€ì„ì— í•¨ìˆ˜ ë°”ì¸ë”©
    self.run_sql = run_sql_postgres
```
- âœ… 11ê°œ DB ì§€ì› (PostgreSQL, MySQL, Snowflake, BigQuery ë“±)
- âœ… Connection ì •ë³´ Closureë¡œ ìº¡ìŠí™”
- âœ… ì½”ë“œ ì¤‘ë³µ ìµœì†Œí™”

---

## ğŸ›ï¸ ì „ì²´ ê³„ì¸µ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Application                                         â”‚
â”‚  vn.ask("ì§€ë‚œë‹¬ ë§¤ì¶œ ìƒìœ„ 10ê°œ ìƒí’ˆì€?")                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  High-Level API (base.py Part 4)                          â”‚
â”‚  - ask(): SQL ìƒì„± â†’ ì‹¤í–‰ â†’ í•™ìŠµ â†’ ì‹œê°í™”               â”‚
â”‚  - train(): Vector Storeì— DDL/SQL ì¶”ê°€                  â”‚
â”‚  - generate_plotly_code(): ì°¨íŠ¸ ìë™ ìƒì„±               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RAG Pipeline (base.py Part 1)                            â”‚
â”‚  1. Retrieval: get_similar_question_sql(question)         â”‚
â”‚                get_related_ddl(question)                   â”‚
â”‚  2. Augmentation: get_sql_prompt(question, examples, ddl) â”‚
â”‚  3. Generation: submit_prompt(prompt) â†’ SQL               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                      â”‚
         â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vector Store     â”‚  â”‚ LLM              â”‚
â”‚ (Mixin)          â”‚  â”‚ (Mixin)          â”‚
â”‚                  â”‚  â”‚                  â”‚
â”‚ ChromaDB:        â”‚  â”‚ OpenAI:          â”‚
â”‚ - add_ddl()      â”‚  â”‚ - submit_prompt()â”‚
â”‚ - add_question_  â”‚  â”‚ - system_message â”‚
â”‚   sql()          â”‚  â”‚ - user_message   â”‚
â”‚ - get_similar_   â”‚  â”‚                  â”‚
â”‚   question_sql() â”‚  â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                      â”‚
         â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ChromaDB         â”‚  â”‚ OpenAI API       â”‚
â”‚ (3 Collections)  â”‚  â”‚ (gpt-3.5/4)      â”‚
â”‚ - sql            â”‚  â”‚                  â”‚
â”‚ - ddl            â”‚  â”‚                  â”‚
â”‚ - documentation  â”‚  â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Database Abstraction (base.py Part 3)                   â”‚
â”‚  - connect_to_postgres() â†’ self.run_sql ë°”ì¸ë”©          â”‚
â”‚  - connect_to_snowflake() â†’ self.run_sql ë°”ì¸ë”©         â”‚
â”‚  - ... (11ê°œ DB)                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ Database       â”‚
                â”‚ (PostgreSQL,   â”‚
                â”‚  Snowflake,    â”‚
                â”‚  BigQuery...)  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ ì£¼ìš” ëª¨ë“ˆ ìƒì„¸

### ğŸ”¹ **RAG Pipeline** (base.py Part 1)

**í•µì‹¬ ë©”ì„œë“œ**: `generate_sql()`

**íë¦„**:
```python
def generate_sql(self, question: str):
    # 1. Retrieval (Vector Search)
    question_sql_list = self.get_similar_question_sql(question)  # ê³¼ê±° ìœ ì‚¬ SQL
    ddl_list = self.get_related_ddl(question)                    # ê´€ë ¨ í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ
    doc_list = self.get_related_documentation(question)          # ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨í…ìŠ¤íŠ¸

    # 2. Augmentation (Prompt êµ¬ì„±)
    prompt = self.get_sql_prompt(
        question=question,
        question_sql_list=question_sql_list,  # Few-shot examples
        ddl_list=ddl_list,                    # í…Œì´ë¸” ì •ì˜
        doc_list=doc_list                     # ì¶”ê°€ ì„¤ëª…
    )

    # 3. Generation (LLM í˜¸ì¶œ)
    llm_response = self.submit_prompt(prompt)  # Abstract method

    # 4. Extraction
    sql = self.extract_sql(llm_response)
    return sql
```

**Two-Step SQL Generation** (ì •í™•ë„ í–¥ìƒ):
```python
# ë¬¸ì œ: LLMì´ ë°ì´í„°ì˜ ì‹¤ì œ ê°’ì„ ëª¨ë¦„
# ì§ˆë¬¸: "John Smithì˜ ì£¼ë¬¸ ë‚´ì—­"
# DB: ì‹¤ì œë¡œëŠ” "john.smith@email.com"ë¡œ ì €ì¥ë¨

# Step 1: Intermediate SQL (ë°ì´í„° í™•ì¸ìš©)
intermediate_sql = "SELECT DISTINCT email FROM users WHERE name LIKE '%John%Smith%'"
df = self.run_sql(intermediate_sql)
# ê²°ê³¼: john.smith@email.com

# Step 2: Final SQL (ì‹¤ì œ ë°ì´í„° í™œìš©)
prompt_with_data = self.add_data_to_prompt(prompt, df)
final_sql = "SELECT * FROM orders WHERE user_email = 'john.smith@email.com'"
```

---

### ğŸ”¹ **Mixin Pattern** (base.py Part 2)

**ë¬¸ì œ**: Vector Storeì™€ LLMì„ ë…ë¦½ì ìœ¼ë¡œ êµ¬í˜„í•˜ê³  ì‹¶ë‹¤

**í•´ê²°**: Abstract Base Class + Mixin

```python
# base.py
class VannaBase(ABC):
    # Vector Store ì¸í„°í˜ì´ìŠ¤
    @abstractmethod
    def add_question_sql(self, question: str, sql: str) -> str:
        pass

    @abstractmethod
    def get_similar_question_sql(self, question: str) -> List[Tuple[str, str]]:
        pass

    # LLM ì¸í„°í˜ì´ìŠ¤
    @abstractmethod
    def submit_prompt(self, prompt: List[dict]) -> str:
        pass

    @abstractmethod
    def system_message(self, message: str) -> dict:
        pass

# chromadb_vector.py
class ChromaDB_VectorStore(VannaBase):
    def add_question_sql(self, question, sql):
        id = deterministic_uuid(json.dumps({"question": question, "sql": sql})) + "-sql"
        self.sql_collection.add(documents=json.dumps(...), ids=id)

    def get_similar_question_sql(self, question):
        results = self.sql_collection.query(query_texts=[question], n_results=10)
        return [(q, s) for q, s in results]

# openai_chat.py
class OpenAI_Chat(VannaBase):
    def submit_prompt(self, prompt):
        response = self.client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=prompt
        )
        return response.choices[0].message.content

    def system_message(self, message):
        return {"role": "system", "content": message}

# ì‚¬ìš©ì ì½”ë“œ (Mixin ì¡°í•©!)
class MyVanna(ChromaDB_VectorStore, OpenAI_Chat):
    def __init__(self, config=None):
        ChromaDB_VectorStore.__init__(self, config=config)
        OpenAI_Chat.__init__(self, config=config)

vn = MyVanna(config={"api_key": "sk-..."})
```

**ì¥ì **:
- âœ… Vector Storeì™€ LLM ì™„ì „íˆ ë…ë¦½
- âœ… ìƒˆ êµ¬í˜„ ì¶”ê°€ ì‹œ base.py ìˆ˜ì • ë¶ˆí•„ìš”
- âœ… ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì¡°í•© ì„ íƒ (ChromaDB + OpenAI, Pinecone + Claude ë“±)

---

### ğŸ”¹ **Token Budget ê´€ë¦¬** (base.py Part 2)

**ë¬¸ì œ**: GPT-3.5-turbo ì»¨í…ìŠ¤íŠ¸ 4K (16K ëª¨ë¸: 16K). ìˆ˜ì‹­ ê°œ í…Œì´ë¸” DDLì„ ëª¨ë‘ ë„£ìœ¼ë©´?

**í•´ê²°**: Dynamic Token Budget
```python
def add_ddl_to_prompt(self, initial_prompt, ddl_list, max_tokens=14000):
    for ddl in ddl_list:
        current = self.str_to_approx_token_count(initial_prompt)
        ddl_tokens = self.str_to_approx_token_count(ddl)

        # Budget ì´ˆê³¼ ì—¬ë¶€ ì²´í¬
        if current + ddl_tokens < max_tokens:
            initial_prompt += f"{ddl}\n\n"
        else:
            break  # ë” ì´ìƒ ì¶”ê°€ ì•ˆ í•¨

    return initial_prompt
```

**ìš°ì„ ìˆœìœ„**:
1. System prompt (í•­ìƒ í¬í•¨)
2. Few-shot examples (ê°€ì¥ ì¤‘ìš”)
3. DDL (ê°€ëŠ¥í•œ ë§Œí¼)
4. Documentation (ì—¬ìœ  ìˆìœ¼ë©´)

---

### ğŸ”¹ **Database Abstraction** (base.py Part 3)

**Dynamic Function Binding**:
```python
def connect_to_postgres(self, host, dbname, user, password, port):
    # Closureë¡œ connection ì •ë³´ ìº¡ìŠí™”
    def connect_to_db():
        return psycopg2.connect(
            host=host,
            dbname=dbname,
            user=user,
            password=password,
            port=port
        )

    def run_sql_postgres(sql: str) -> pd.DataFrame:
        conn = connect_to_db()  # Closure!
        cs = conn.cursor()
        cs.execute(sql)
        results = cs.fetchall()
        columns = [desc[0] for desc in cs.description]
        return pd.DataFrame(results, columns=columns)

    # ëŸ°íƒ€ì„ì— í•¨ìˆ˜ ë°”ì¸ë”©!
    self.run_sql = run_sql_postgres
    self.run_sql_is_set = True
```

**ì§€ì› DB** (11ê°œ):
- PostgreSQL, MySQL, SQLite, Snowflake, BigQuery
- DuckDB, ClickHouse, Oracle, Hive, Presto, Databricks

---

### ğŸ”¹ **High-Level API** (base.py Part 4)

**Pipeline íŒ¨í„´**: `ask()` ë©”ì„œë“œê°€ 6ë‹¨ê³„ í†µí•©
```python
def ask(self, question, print_results=True, auto_train=True, visualize=True):
    # 1. Generate SQL
    sql = self.generate_sql(question)

    # 2. Execute
    df = self.run_sql(sql)

    # 3. Auto-train (ì„±ê³µí•œ SQL ìë™ í•™ìŠµ)
    if len(df) > 0 and auto_train:
        self.add_question_sql(question, sql)

    # 4. Generate Plotly code
    if visualize:
        plotly_code = self.generate_plotly_code(
            question=question,
            sql=sql,
            df=df
        )

        # 5. Execute Plotly code (with graceful degradation)
        try:
            fig = self.get_plotly_figure(plotly_code, df)
        except Exception as e:
            fig = None  # ì°¨íŠ¸ ì‹¤íŒ¨í•´ë„ ë°ì´í„°ëŠ” ë°˜í™˜

    # 6. Return all
    return sql, df, fig
```

**Training Plan** (Preview-Modify-Execute íŒ¨í„´):
```python
# 1. Plan ìƒì„± (DB ë©”íƒ€ë°ì´í„° ìë™ ìŠ¤ìº”)
plan = vn.get_training_plan_postgres(
    filter_schemas=["public"],
    use_historical_queries=True
)

# 2. Preview
print(plan.get_summary())
# Train on DDL: public users
# Train on DDL: public orders
# Train on DDL: public temp_table

# 3. Modify
plan.remove_item("Train on DDL: public temp_table")

# 4. Execute
vn.train(plan=plan)
```

---

### ğŸ”¹ **ChromaDB Vector Store** (chromadb_vector.py)

**3-Collection ë¶„ë¦¬**:
```python
self.sql_collection = chroma_client.get_or_create_collection("sql")
self.ddl_collection = chroma_client.get_or_create_collection("ddl")
self.documentation_collection = chroma_client.get_or_create_collection("documentation")
```

**ì´ìœ **:
- SQL: ì§ˆë¬¸-SQL ìŒ (Few-shot learning)
- DDL: í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ (CREATE TABLE ...)
- Documentation: ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨í…ìŠ¤íŠ¸ ("revenueëŠ” VAT ì œì™¸")

**Deterministic UUID** (ìë™ ì¤‘ë³µ ì œê±°):
```python
def add_ddl(self, ddl: str) -> str:
    id = deterministic_uuid(ddl) + "-ddl"
    self.ddl_collection.add(documents=ddl, ids=id)
    return id

# ê°™ì€ DDL ì¶”ê°€ ì‹œ â†’ ê°™ì€ UUID â†’ ChromaDBê°€ ìë™ ì—…ë°ì´íŠ¸
```

---

### ğŸ”¹ **OpenAI LLM** (openai_chat.py)

**ìë™ ëª¨ë¸ ì„ íƒ** (ë¹„ìš© ìµœì í™”):
```python
def submit_prompt(self, prompt):
    # í† í° ìˆ˜ ê·¼ì‚¬ì¹˜
    num_tokens = sum(len(m["content"]) / 4 for m in prompt)

    # 3500 í† í° ê¸°ì¤€ìœ¼ë¡œ ëª¨ë¸ ì„ íƒ
    if num_tokens > 3500:
        model = "gpt-3.5-turbo-16k"  # ë¹„ì‹¼ ëª¨ë¸
    else:
        model = "gpt-3.5-turbo"      # ì €ë ´í•œ ëª¨ë¸

    response = self.client.chat.completions.create(
        model=model,
        messages=prompt,
        temperature=self.temperature
    )
    return response.choices[0].message.content
```

**ë¹„ìš© ë¹„êµ**:
- gpt-3.5-turbo: $0.001 / 1K tokens
- gpt-3.5-turbo-16k: $0.002 / 1K tokens
- gpt-4: $0.03 / 1K tokens (30ë°°!)

**Azure OpenAI í˜¸í™˜**:
```python
# kwargs ìš°ì„ ìˆœìœ„: kwargs > config > ìë™ ì„ íƒ
if kwargs.get("model"):
    model = kwargs["model"]
elif kwargs.get("engine"):  # Azure OpenAI
    engine = kwargs["engine"]
elif self.config.get("model"):
    model = self.config["model"]
else:
    # ìë™ ì„ íƒ
```

---

### ğŸ”¹ **API ë§ˆì´ê·¸ë ˆì´ì…˜** (__init__.py)

**ë¬¸ì œ**: v0.xëŠ” global í•¨ìˆ˜, v1.0ì€ ì¸ìŠ¤í„´ìŠ¤. ê¸°ì¡´ ì‚¬ìš©ì ì½”ë“œ ì²˜ë¦¬?

**í•´ê²°**: Breaking Change + ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€
```python
def error_deprecation():
    raise Exception("""
Please switch to the following method for initializing Vanna:

from vanna.remote import VannaDefault

api_key = # Your API key from https://vanna.ai/account/profile
vanna_model_name = # Your model name from https://vanna.ai/account/profile

vn = VannaDefault(model=vanna_model_name, api_key=api_key)
""")

# ëª¨ë“  ë ˆê±°ì‹œ í•¨ìˆ˜ (30ê°œ ì´ìƒ)
def set_api_key(key: str) -> None:
    error_deprecation()

def generate_sql(question: str) -> str:
    error_deprecation()
```

**íš¨ê³¼**:
- ì‚¬ìš©ìê°€ ì¦‰ì‹œ ë§ˆì´ê·¸ë ˆì´ì…˜
- ê¸°ìˆ  ë¶€ì±„ ë¹ ë¥´ê²Œ ì œê±°
- ì½”ë“œë² ì´ìŠ¤ ì •ë¦¬

**OTP ì¸ì¦** (Vanna.AI Cloud):
```python
def get_api_key(email: str, otp_code=None) -> str:
    # 1. í™˜ê²½ ë³€ìˆ˜ ì²´í¬
    if os.environ.get("VANNA_API_KEY"):
        return os.environ["VANNA_API_KEY"]

    # 2. OTP ì „ì†¡
    __unauthenticated_rpc_call("send_otp", [UserEmail(email=email)])

    # 3. OTP ì…ë ¥
    otp_code = input("Check your email for the code and enter it here: ")

    # 4. API Key ë°œê¸‰
    key = __unauthenticated_rpc_call("verify_otp", [UserOTP(email=email, otp=otp_code)])
    return key["key"]
```

---

## ğŸ¨ í•µì‹¬ ì„¤ê³„ íŒ¨í„´

### 1. **Mixin íŒ¨í„´** (êµ¬ì¡°ì  ë…ë¦½ì„±)
**ëª©ì **: Vector Storeì™€ LLMì„ ë…ë¦½ì ìœ¼ë¡œ ì¡°í•©

**êµ¬í˜„**:
```python
class VannaBase(ABC):
    @abstractmethod
    def abstract_method(self): pass

class FeatureA(VannaBase):
    def method_a(self): ...

class FeatureB(VannaBase):
    def method_b(self): ...

class Combined(FeatureA, FeatureB):
    pass  # ì¡°í•©!
```

**ì ìš©**:
- ChromaDB + OpenAI
- Pinecone + Anthropic
- Custom Vector Store + Local LLM

---

### 2. **RAG Pipeline** (ì •í™•ë„ í–¥ìƒ)
**ëª©ì **: Fine-tuning ì—†ì´ ë†’ì€ ì •í™•ë„

**íë¦„**:
```
ì§ˆë¬¸ â†’ Retrieval (Vector Search) â†’ Augmentation (Prompt) â†’ Generation (LLM) â†’ SQL
```

**í•µì‹¬**:
- Few-shot learning (ê³¼ê±° SQL ì˜ˆì‹œ)
- ê´€ë ¨ DDLë§Œ í¬í•¨ (Token budget)
- Two-step generation (ë°ì´í„° í™•ì¸ â†’ ì •í™•í•œ SQL)

---

### 3. **Dynamic Function Binding** (DB ë…ë¦½ì„±)
**ëª©ì **: 11ê°œ DBë¥¼ ë‹¨ì¼ ì¸í„°í˜ì´ìŠ¤ë¡œ

**êµ¬í˜„**:
```python
def connect_to_db():
    conn = psycopg2.connect(...)  # Connection ì •ë³´ ìº¡ìŠí™”
    return conn

def run_sql(sql):
    conn = connect_to_db()  # Closure!
    ...

self.run_sql = run_sql  # ëŸ°íƒ€ì„ ë°”ì¸ë”©
```

**ì¥ì **:
- Connection pool ìº¡ìŠí™”
- DBë³„ ì½”ë“œ ì¤‘ë³µ ìµœì†Œí™”
- ì‚¬ìš©ìëŠ” connection ê´€ë¦¬ ë¶ˆí•„ìš”

---

### 4. **Token Budget ê´€ë¦¬** (ë¹„ìš© ìµœì í™”)
**ëª©ì **: LLM ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ ëŒ€ì‘

**êµ¬í˜„**:
```python
for item in items:
    if current_tokens + item_tokens < max_tokens:
        prompt += item
    else:
        break
```

**ìš°ì„ ìˆœìœ„**:
1. System prompt (í•„ìˆ˜)
2. Few-shot examples (ì •í™•ë„ì— ê°€ì¥ ì¤‘ìš”)
3. DDL (ê´€ë ¨ í…Œì´ë¸”ë§Œ)
4. Documentation (ì—¬ìœ  ìˆìœ¼ë©´)

---

### 5. **Pipeline íŒ¨í„´** (ì‚¬ìš© í¸ì˜ì„±)
**ëª©ì **: ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ë‹¨ì¼ APIë¡œ

**êµ¬í˜„**:
```python
def ask(question):
    sql = self.generate_sql(question)         # Step 1
    df = self.run_sql(sql)                    # Step 2
    if auto_train: self.add_question_sql()    # Step 3
    if visualize: fig = self.generate_chart() # Step 4
    return sql, df, fig
```

**íš¨ê³¼**:
- 6ë‹¨ê³„ â†’ 1ì¤„
- ì‚¬ìš©ìëŠ” ë³µì¡ë„ ëª°ë¼ë„ ë¨

---

### 6. **Preview-Modify-Execute** (ì‚¬ìš©ì ì œì–´)
**ëª©ì **: ìë™í™” + ì‚¬ìš©ì ì œì–´ ê· í˜•

**êµ¬í˜„**:
```python
plan = create_plan()        # 1. Preview
plan.remove_item("...")     # 2. Modify
execute(plan)               # 3. Execute
```

**ì ìš©**:
- Training Plan (ìˆ˜ë°± ê°œ í…Œì´ë¸” í•™ìŠµ)
- Bulk operations (í™•ì¸ í›„ ì‹¤í–‰)

---

## ğŸ“Š ì„±ëŠ¥ íŠ¹ì„±

### Token Budget ì˜í–¥
- **Small context** (< 2K tokens): gpt-3.5-turbo
- **Medium context** (2K-4K): gpt-3.5-turbo
- **Large context** (4K-16K): gpt-3.5-turbo-16k (ìë™ ì„ íƒ)

### ë¹„ìš© ìµœì í™”
- ìë™ ëª¨ë¸ ì„ íƒ: 30-50% ë¹„ìš© ì ˆê°
- Token budget ê´€ë¦¬: ë¶ˆí•„ìš”í•œ DDL ì œì™¸
- ìºì‹± (Redis): 20-40% ìºì‹œ íˆíŠ¸

### ì •í™•ë„
- RAG (Few-shot): ê¸°ë³¸ ì •í™•ë„ 70-80%
- Two-step SQL: ì •í™•ë„ 85-90%ë¡œ í–¥ìƒ
- Domainë³„ ëª¨ë¸ ë¶„ë¦¬: 90-95%

---

## ğŸ”§ í™•ì¥ í¬ì¸íŠ¸

### 1. Custom Vector Store êµ¬í˜„
```python
class MyVectorStore(VannaBase):
    def add_question_sql(self, question, sql):
        # Pinecone, Qdrant, Weaviate ë“±
        pass

    def get_similar_question_sql(self, question):
        pass
```

### 2. Custom LLM êµ¬í˜„
```python
class MyLLM(VannaBase):
    def submit_prompt(self, prompt):
        # Anthropic, Cohere, Local LLM ë“±
        pass
```

### 3. Custom Database ì—°ê²°
```python
def connect_to_custom_db(self, connection_string):
    def run_sql_custom(sql):
        # ìƒˆë¡œìš´ DB ì—°ê²°
        pass

    self.run_sql = run_sql_custom
```

---

## ğŸ“ ìš”ì•½

| ì¸¡ë©´ | ë‚´ìš© |
|------|------|
| **í•µì‹¬ ëª©ì ** | ìì—°ì–´ â†’ SQL (RAG ê¸°ë°˜) |
| **ì£¼ìš” ë¬¸ì œ** | Fine-tuning ë¹„ìš©, Vector Store/LLM ì¢…ì†ì„±, DB ë…ë¦½ì„± |
| **í•´ê²° ë°©ë²•** | RAG, Mixin íŒ¨í„´, Dynamic Binding, Token Budget |
| **í•µì‹¬ íŒ¨í„´** | Mixin, RAG Pipeline, Closure, Pipeline, Preview-Modify-Execute |
| **í™•ì¥ì„±** | Vector Store, LLM, Database ëª¨ë‘ êµì²´ ê°€ëŠ¥ |
| **ì„±ëŠ¥** | Token budget ê´€ë¦¬ + ìë™ ëª¨ë¸ ì„ íƒ |
| **ë¹„ìš© ìµœì í™”** | 30-50% (ìë™ ëª¨ë¸ ì„ íƒ + ìºì‹±) |
| **ì •í™•ë„** | 70-95% (RAG + Two-step + Domain ë¶„ë¦¬) |

**í•œ ì¤„ ìš”ì•½**: Mixin íŒ¨í„´ê³¼ RAGë¥¼ í™œìš©í•˜ì—¬ Vector Storeì™€ LLMì„ ììœ ë¡­ê²Œ ì¡°í•©í•˜ëŠ” Text-to-SQL í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
