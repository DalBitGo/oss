"""
ë¯¸ë‹ˆ LLM í¬ë¡¤ëŸ¬ - crawl4ai í•µì‹¬ë§Œ ì¶”ì¶œí•œ ê°€ë²¼ìš´ ë²„ì „

ëª©í‘œ: URL â†’ LLM ì¹œí™”ì  Markdown
"""

import asyncio
from playwright.async_api import async_playwright
import html2text
from bs4 import BeautifulSoup


async def crawl(url: str) -> str:
    """
    URLì„ ë°›ì•„ì„œ Markdownìœ¼ë¡œ ë°˜í™˜

    Args:
        url: í¬ë¡¤ë§í•  URL

    Returns:
        í˜ì´ì§€ ë‚´ìš©ì„ Markdownìœ¼ë¡œ ë³€í™˜í•œ ë¬¸ìì—´
    """
    async with async_playwright() as p:
        # 1. ë¸Œë¼ìš°ì € ì‹œì‘ (headless)
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()

        # 2. í˜ì´ì§€ ë¡œë“œ
        await page.goto(url, wait_until="domcontentloaded")

        # 3. HTML ê°€ì ¸ì˜¤ê¸°
        html = await page.content()

        # 4. ë¸Œë¼ìš°ì € ì¢…ë£Œ
        await browser.close()

        # 5. HTML â†’ Markdown ë³€í™˜
        markdown = html_to_markdown(html)

        return markdown


def clean_html(html: str) -> str:
    """ë…¸ì´ì¦ˆ ì œê±° (nav, footer, script ë“±)"""
    soup = BeautifulSoup(html, "html.parser")

    # ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±°
    for tag in soup.find_all(["script", "style", "nav", "footer", "header", "aside"]):
        tag.decompose()

    # ê´‘ê³ /íŒì—… ê´€ë ¨ í´ë˜ìŠ¤ ì œê±°
    for element in soup.find_all(class_=lambda x: x and any(
        keyword in x.lower() for keyword in ["ad", "popup", "modal", "banner", "cookie"]
    )):
        element.decompose()

    return str(soup)


def html_to_markdown(html: str) -> str:
    """HTMLì„ Markdownìœ¼ë¡œ ë³€í™˜"""
    # 1. ë…¸ì´ì¦ˆ ì œê±°
    cleaned = clean_html(html)

    # 2. html2text ì„¤ì •
    h = html2text.HTML2Text()
    h.ignore_links = False
    h.ignore_images = False
    h.body_width = 0  # ì¤„ë°”ê¿ˆ ì—†ì´
    h.single_line_break = True

    # 3. ë³€í™˜
    markdown = h.handle(cleaned)

    return markdown.strip()


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    import sys

    # ì¸ìë¡œ URL ë°›ê±°ë‚˜ ê¸°ë³¸ê°’ ì‚¬ìš©
    test_url = sys.argv[1] if len(sys.argv) > 1 else "https://example.com"

    print(f"ğŸ” í¬ë¡¤ë§: {test_url}\n")
    print("=" * 50)

    result = asyncio.run(crawl(test_url))
    print(result)

    print("=" * 50)
    print(f"\nğŸ“Š ê²°ê³¼: {len(result)} ê¸€ì")
