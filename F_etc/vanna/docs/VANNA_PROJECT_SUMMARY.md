# Vanna Project - ì „ì²´ ìš”ì•½

## í”„ë¡œì íŠ¸ ê°œìš”

**Vanna**ëŠ” ìì—°ì–´ë¥¼ SQLë¡œ ë³€í™˜í•˜ëŠ” Text-to-SQL í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. RAG (Retrieval-Augmented Generation)ë¥¼ í™œìš©í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆë¥¼ í•™ìŠµí•˜ê³ , ì‚¬ìš©ì ì§ˆë¬¸ì— ë§ëŠ” SQLì„ ìƒì„±í•©ë‹ˆë‹¤.

**í•µì‹¬ íŠ¹ì§•**:
- ğŸ”Œ **í”ŒëŸ¬ê·¸ì¸ ì•„í‚¤í…ì²˜**: Vector Storeì™€ LLMì„ ììœ ë¡­ê²Œ ì¡°í•©
- ğŸ¯ **RAG ê¸°ë°˜**: Fine-tuning ì—†ì´ë„ ë†’ì€ ì •í™•ë„
- ğŸ—„ï¸ **11ê°œ DB ì§€ì›**: PostgreSQL, MySQL, Snowflake, BigQuery ë“±
- ğŸ“Š **ì‹œê°í™” ìë™ ìƒì„±**: Plotly ì°¨íŠ¸ ì½”ë“œ ìë™ ìƒì„±
- â˜ï¸ **Cloud + Local**: Vanna.AI Cloud ë˜ëŠ” Self-hosted

---

## ì•„í‚¤í…ì²˜ ì „ì²´ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        User Application                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ ask("ì§€ë‚œë‹¬ ë§¤ì¶œ ìƒìœ„ 10ê°œ ìƒí’ˆì€?")
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   VannaBase (base/base.py)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  High-Level API: ask(), train(), generate_sql()          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  RAG Pipeline: Retrieval â†’ Augmentation â†’ Generation     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Database Abstraction: 11 DB connections (dynamic bind)  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Abstract Methods (êµ¬í˜„ í•„ìš”)                              â”‚  â”‚
â”‚  â”‚  - submit_prompt()        (LLM êµ¬í˜„)                      â”‚  â”‚
â”‚  â”‚  - add_question_sql()     (Vector Store êµ¬í˜„)            â”‚  â”‚
â”‚  â”‚  - add_ddl()              (Vector Store êµ¬í˜„)            â”‚  â”‚
â”‚  â”‚  - get_similar_question_sql() (Vector Store êµ¬í˜„)        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚                      â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                      â–¼    â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ChromaDB_Vector  â”‚  â”‚   OpenAI_Chat    â”‚ â”‚  Other LLMs      â”‚
â”‚ Store            â”‚  â”‚                  â”‚ â”‚ (Anthropic, etc) â”‚
â”‚ (chromadb/       â”‚  â”‚ (openai/         â”‚ â”‚                  â”‚
â”‚  chromadb_       â”‚  â”‚  openai_chat.py) â”‚ â”‚                  â”‚
â”‚  vector.py)      â”‚  â”‚                  â”‚ â”‚                  â”‚
â”‚                  â”‚  â”‚                  â”‚ â”‚                  â”‚
â”‚ - 3 collections  â”‚  â”‚ - Auto model     â”‚ â”‚                  â”‚
â”‚ - Deterministic  â”‚  â”‚   selection      â”‚ â”‚                  â”‚
â”‚   UUID           â”‚  â”‚ - Azure support  â”‚ â”‚                  â”‚
â”‚ - Persistent/    â”‚  â”‚ - Token counting â”‚ â”‚                  â”‚
â”‚   In-memory      â”‚  â”‚                  â”‚ â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                      â”‚                      â”‚
         â”‚                      â”‚                      â”‚
         â–¼                      â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ChromaDB       â”‚  â”‚         OpenAI API                   â”‚
â”‚   (Local/Remote) â”‚  â”‚         (gpt-3.5-turbo, gpt-4)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ì‚¬ìš©ì ì½”ë“œ (Mixin íŒ¨í„´)                        â”‚
â”‚                                                                  â”‚
â”‚  class MyVanna(ChromaDB_VectorStore, OpenAI_Chat):              â”‚
â”‚      def __init__(self, config=None):                           â”‚
â”‚          ChromaDB_VectorStore.__init__(self, config)            â”‚
â”‚          OpenAI_Chat.__init__(self, config)                     â”‚
â”‚                                                                  â”‚
â”‚  vn = MyVanna(config={"api_key": "sk-...", "model": "gpt-4"})  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## í•µì‹¬ ì„¤ê³„ ê²°ì •

### 1. Mixin íŒ¨í„´ (ê°€ì¥ ì¤‘ìš”!)

**ë¬¸ì œ**: Vector Storeì™€ LLMì„ ë…ë¦½ì ìœ¼ë¡œ ì¡°í•©í•˜ê³  ì‹¶ë‹¤

**í•´ê²°**: Abstract Base Class + Mixin íŒ¨í„´

```python
# base.py
class VannaBase(ABC):
    @abstractmethod
    def submit_prompt(self, prompt) -> str:
        """LLM êµ¬í˜„ í•„ìš”"""
        pass

    @abstractmethod
    def add_question_sql(self, question: str, sql: str) -> str:
        """Vector Store êµ¬í˜„ í•„ìš”"""
        pass

# ì‚¬ìš©ì ì½”ë“œ
class MyVanna(ChromaDB_VectorStore, OpenAI_Chat):
    pass  # ë‘ Mixinì´ VannaBaseë¥¼ ì™„ì„±

vn = MyVanna()
```

**ì¥ì **:
- Vector Storeì™€ LLMì„ ììœ ë¡­ê²Œ ì¡°í•©
- ìƒˆë¡œìš´ êµ¬í˜„ ì¶”ê°€ ì‹œ base.py ìˆ˜ì • ë¶ˆí•„ìš”
- ë‹¨ì¼ ì±…ì„ ì›ì¹™ (SRP)

**ì¡°í•© ì˜ˆì‹œ**:
- ChromaDB + OpenAI
- Pinecone + Anthropic Claude
- Qdrant + Local LLM
- Custom Vector Store + Custom LLM

**ê´€ë ¨ íŒŒì¼**:
- `base.py` (2118ì¤„) - Abstract methods ì •ì˜
- `chromadb_vector.py` (257ì¤„) - Vector Store êµ¬í˜„
- `openai_chat.py` (128ì¤„) - LLM êµ¬í˜„

---

### 2. RAG vs Fine-tuning

**ë¬¸ì œ**: ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆë¥¼ LLMì—ê²Œ ì–´ë–»ê²Œ í•™ìŠµì‹œí‚¬ê¹Œ?

**Option A: Fine-tuning**
- ì¥ì : ë†’ì€ ì •í™•ë„
- ë‹¨ì : ë¹„ìš©, ì‹œê°„, ìŠ¤í‚¤ë§ˆ ë³€ê²½ ì‹œ ì¬í•™ìŠµ í•„ìš”

**Option B: RAG (Retrieval-Augmented Generation)** âœ…
- ì¥ì : ì¦‰ì‹œ ì—…ë°ì´íŠ¸, ë‚®ì€ ë¹„ìš©
- ë‹¨ì : í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì œí•œ

**Vannaì˜ ì„ íƒ**: RAG

**êµ¬í˜„** (base.py:93-267):
```python
def generate_sql(self, question: str):
    # 1. Retrieval (Vector Search)
    question_sql_list = self.get_similar_question_sql(question)
    ddl_list = self.get_related_ddl(question)
    doc_list = self.get_related_documentation(question)

    # 2. Augmentation (Prompt êµ¬ì„±)
    prompt = self.get_sql_prompt(
        question=question,
        question_sql_list=question_sql_list,
        ddl_list=ddl_list,
        doc_list=doc_list
    )

    # 3. Generation (LLM í˜¸ì¶œ)
    llm_response = self.submit_prompt(prompt)

    # 4. Extraction
    sql = self.extract_sql(llm_response)
    return sql
```

**Vector Store êµ¬ì¡°** (chromadb_vector.py):
```python
# 3ê°œì˜ Collectionìœ¼ë¡œ ë¶„ë¦¬
self.sql_collection = chroma_client.get_or_create_collection("sql")
self.ddl_collection = chroma_client.get_or_create_collection("ddl")
self.documentation_collection = chroma_client.get_or_create_collection("documentation")
```

**ê²€ìƒ‰ ë¡œì§**:
- ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ê³¼ê±° SQL ê²€ìƒ‰ (Few-shot learning)
- ê´€ë ¨ í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰ (DDL)
- ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ (Documentation)

**ê´€ë ¨ íŒŒì¼**:
- `base.py` - Part 1: RAG workflow (lines 93-382)
- `chromadb_vector.py` - Vector Store êµ¬í˜„

---

### 3. Dynamic Function Binding (Database ë…ë¦½ì„±)

**ë¬¸ì œ**: 11ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ DB APIë¥¼ ì–´ë–»ê²Œ í†µí•©í• ê¹Œ?

**Option A: Adapter íŒ¨í„´ (ê° DBë§ˆë‹¤ í´ë˜ìŠ¤)**
```python
class PostgresAdapter:
    def run_sql(self, sql): ...

class MySQLAdapter:
    def run_sql(self, sql): ...
```
- ì¥ì : ëª…í™•í•œ ë¶„ë¦¬
- ë‹¨ì : í´ë˜ìŠ¤ í­ë°œ, ì½”ë“œ ì¤‘ë³µ

**Option B: Dynamic Function Binding** âœ…
```python
def connect_to_postgres(self, host, dbname, user, password, port):
    def connect_to_db():
        return psycopg2.connect(host=host, dbname=dbname, ...)

    def run_sql_postgres(sql: str) -> pd.DataFrame:
        conn = connect_to_db()
        cs = conn.cursor()
        cs.execute(sql)
        results = cs.fetchall()
        columns = [desc[0] for desc in cs.description]
        return pd.DataFrame(results, columns=columns)

    # ëŸ°íƒ€ì„ì— í•¨ìˆ˜ë¥¼ ì¸ìŠ¤í„´ìŠ¤ ë©”ì„œë“œë¡œ ë°”ì¸ë”©!
    self.run_sql = run_sql_postgres
    self.run_sql_is_set = True
```
- ì¥ì : ì½”ë“œ ê°„ê²°, Closureë¡œ connection ìº¡ìŠí™”
- ë‹¨ì : ëŸ°íƒ€ì„ ë°”ì¸ë”© (IDE ìë™ì™„ì„± ì–´ë ¤ì›€)

**ì§€ì› DB**:
- PostgreSQL, MySQL, SQLite, Snowflake, BigQuery
- DuckDB, ClickHouse, Oracle, Hive, Presto, Databricks

**ê´€ë ¨ íŒŒì¼**:
- `base.py` - Part 3: Database (lines 761-1682)

---

### 4. Two-Step SQL Generation (ì •í™•ë„ í–¥ìƒ)

**ë¬¸ì œ**: LLMì´ ë°ì´í„°ì˜ ì‹¤ì œ ê°’ì„ ëª¨ë¥´ë©´ ì •í™•í•œ SQLì„ ìƒì„±í•˜ê¸° ì–´ë µë‹¤

**ì˜ˆì‹œ**:
```
ì§ˆë¬¸: "John Smithì˜ ì£¼ë¬¸ ë‚´ì—­ì„ ë³´ì—¬ì¤˜"
ë¬¸ì œ: DBì—ëŠ” "john.smith@email.com"ë¡œ ì €ì¥ë˜ì–´ ìˆìŒ (ì´ë¦„ì´ ì•„ë‹Œ ì´ë©”ì¼)
```

**í•´ê²°**: Intermediate SQL

```python
def generate_sql(self, question: str, allow_llm_to_see_data=False):
    # 1ì°¨: LLMì´ Intermediate SQL ìƒì„±
    llm_response = self.submit_prompt(prompt)

    if self.is_sql_valid(llm_response) and 'intermediate_sql' in llm_response:
        # 2. Intermediate SQL ì‹¤í–‰
        intermediate_sql = self.extract_sql(llm_response)
        df = self.run_sql(intermediate_sql)

        # 3. ë°ì´í„°ë¥¼ ë³´ê³  Final SQL ìƒì„±
        prompt_with_data = self.add_data_to_prompt(prompt, df)
        llm_response = self.submit_prompt(prompt_with_data)

    return self.extract_sql(llm_response)
```

**íë¦„**:
```
ì§ˆë¬¸: "John Smithì˜ ì£¼ë¬¸ ë‚´ì—­"
â†“
LLM: Intermediate SQL ìƒì„±
  SELECT DISTINCT email FROM users WHERE name LIKE '%John%Smith%'
â†“
ì‹¤í–‰ ê²°ê³¼: john.smith@email.com
â†“
LLM: Final SQL ìƒì„± (ì‹¤ì œ ë°ì´í„° í™œìš©)
  SELECT * FROM orders WHERE user_email = 'john.smith@email.com'
```

**ê´€ë ¨ íŒŒì¼**:
- `base.py` - Part 1: RAG workflow (lines 131-267)

---

### 5. Token Budget ê´€ë¦¬

**ë¬¸ì œ**: GPT-3.5-turboì˜ ì»¨í…ìŠ¤íŠ¸ëŠ” 4K (16K ëª¨ë¸: 16K). ìˆ˜ì‹­ ê°œì˜ í…Œì´ë¸” DDLì„ ëª¨ë‘ ë„£ìœ¼ë©´?

**í•´ê²°**: Dynamic Token Budget

```python
def add_ddl_to_prompt(
    self,
    initial_prompt: str,
    ddl_list: list,
    max_tokens: int = 14000
) -> str:
    if len(ddl_list) > 0:
        initial_prompt += "\n\nYou may use the following DDL statements as a reference:\n\n"

    for ddl in ddl_list:
        # í˜„ì¬ í”„ë¡¬í”„íŠ¸ í† í° ìˆ˜
        current_tokens = self.str_to_approx_token_count(initial_prompt)

        # DDL ì¶”ê°€ ì‹œ í† í° ìˆ˜
        ddl_tokens = self.str_to_approx_token_count(ddl)

        # Budget ì´ˆê³¼ ì—¬ë¶€ ì²´í¬
        if current_tokens + ddl_tokens < max_tokens:
            initial_prompt += f"{ddl}\n\n"
        else:
            # Budget ì´ˆê³¼ â†’ ë” ì´ìƒ ì¶”ê°€ ì•ˆ í•¨
            break

    return initial_prompt
```

**ìš°ì„ ìˆœìœ„**:
1. System prompt (í•­ìƒ í¬í•¨)
2. Few-shot examples (ê°€ì¥ ì¤‘ìš”)
3. DDL (ê°€ëŠ¥í•œ ë§Œí¼)
4. Documentation (ê°€ëŠ¥í•œ ë§Œí¼)

**í† í° ê³„ì‚°**:
```python
def str_to_approx_token_count(self, string: str) -> int:
    return len(string) / 4  # ê·¼ì‚¬ì¹˜: 4 chars â‰ˆ 1 token
```

**ê´€ë ¨ íŒŒì¼**:
- `base.py` - Part 2: Abstraction (lines 606-693)
- `openai_chat.py` - ìë™ ëª¨ë¸ ì„ íƒ (3500 í† í° ê¸°ì¤€)

---

### 6. Training Plan (ëŒ€ëŸ‰ í•™ìŠµ)

**ë¬¸ì œ**: ìˆ˜ë°± ê°œì˜ í…Œì´ë¸”ì„ ëª¨ë‘ í•™ìŠµí•˜ë©´ ë¹„ìš©ê³¼ ì‹œê°„ì´ ë§ì´ ë“ ë‹¤

**í•´ê²°**: Preview â†’ Modify â†’ Execute íŒ¨í„´

```python
# 1. Plan ìƒì„± (DB ë©”íƒ€ë°ì´í„° ìë™ ìŠ¤ìº”)
plan = vn.get_training_plan_postgres(
    filter_schemas=["public"],
    use_historical_queries=True
)

# 2. Preview
print(plan.get_summary())
# Train on DDL: public users
# Train on DDL: public orders
# Train on DDL: public temp_table  â† ì œê±°í•˜ê³  ì‹¶ìŒ

# 3. Modify
plan.remove_item("Train on DDL: public temp_table")

# 4. Execute
vn.train(plan=plan)
```

**TrainingPlan êµ¬ì¡°** (__init__.py:171-250):
```python
@dataclass
class TrainingPlanItem:
    item_type: str      # "sql", "ddl", "is"
    item_group: str     # Schema
    item_name: str      # Table name
    item_value: str     # Actual DDL

class TrainingPlan:
    _plan: List[TrainingPlanItem]

    def get_summary(self) -> List[str]:
        return [str(item) for item in self._plan]

    def remove_item(self, item: str):
        # ë¶ˆí•„ìš”í•œ í•­ëª© ì œê±°
        for plan_item in self._plan:
            if str(plan_item) == item:
                self._plan.remove(plan_item)
```

**ì¥ì **:
- ìë™í™” (DB ìŠ¤ìº”)
- íˆ¬ëª…ì„± (ë¬´ì—‡ì„ í•™ìŠµí• ì§€ ë¯¸ë¦¬ í™•ì¸)
- ì œì–´ (ë¶ˆí•„ìš”í•œ í•­ëª© ì œê±°)

**ê´€ë ¨ íŒŒì¼**:
- `__init__.py` - TrainingPlan í´ë˜ìŠ¤ ì •ì˜
- `base.py` - Part 4: High-level API (train ë©”ì„œë“œ)

---

### 7. API ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ

**ë¬¸ì œ**: Vanna v0.xëŠ” global í•¨ìˆ˜ ë°©ì‹, v1.0ì€ ì¸ìŠ¤í„´ìŠ¤ ë°©ì‹. ê¸°ì¡´ ì‚¬ìš©ì ì½”ë“œë¥¼ ì–´ë–»ê²Œ ì²˜ë¦¬?

**í•´ê²°**: Breaking Change + ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€

```python
def error_deprecation():
    raise Exception("""
Please switch to the following method for initializing Vanna:

from vanna.remote import VannaDefault

api_key = # Your API key from https://vanna.ai/account/profile
vanna_model_name = # Your model name from https://vanna.ai/account/profile

vn = VannaDefault(model=vanna_model_name, api_key=api_key)
""")

# ëª¨ë“  ë ˆê±°ì‹œ í•¨ìˆ˜
def set_api_key(key: str) -> None:
    error_deprecation()

def generate_sql(question: str) -> str:
    error_deprecation()

# ... 30ê°œ ì´ìƒì˜ í•¨ìˆ˜ê°€ ë™ì¼
```

**Deprecation ë ˆë²¨**:
1. ë¬¸ì„œì—ë§Œ ëª…ì‹œ (ì•½í•¨)
2. Warning ë¡œê·¸ (ì¤‘ê°„)
3. DeprecationWarning (ê°•í•¨)
4. **ì¦‰ì‹œ Error** âœ… (ë§¤ìš° ê°•í•¨) â† Vannaì˜ ì„ íƒ

**íš¨ê³¼**:
- ì‚¬ìš©ìê°€ ì¦‰ì‹œ ë§ˆì´ê·¸ë ˆì´ì…˜
- ê¸°ìˆ  ë¶€ì±„ ë¹ ë¥´ê²Œ ì œê±°
- ì½”ë“œë² ì´ìŠ¤ ì •ë¦¬

**ê´€ë ¨ íŒŒì¼**:
- `__init__.py` - ëª¨ë“  ë ˆê±°ì‹œ í•¨ìˆ˜ê°€ deprecated

---

## íŒŒì¼ë³„ ì—­í•  ìš”ì•½

| íŒŒì¼ | ë¼ì¸ ìˆ˜ | ì—­í•  | í•µì‹¬ íŒ¨í„´ |
|------|---------|------|-----------|
| `base.py` | 2118 | í•µì‹¬ í”„ë ˆì„ì›Œí¬ | RAG, Mixin, Dynamic Binding, Pipeline |
| `chromadb_vector.py` | 257 | Vector Store êµ¬í˜„ | 3-collection ë¶„ë¦¬, Deterministic UUID |
| `openai_chat.py` | 128 | LLM êµ¬í˜„ | Client ì£¼ì…, ìë™ ëª¨ë¸ ì„ íƒ, Azure í˜¸í™˜ |
| `__init__.py` | 399 | ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸ | API ë§ˆì´ê·¸ë ˆì´ì…˜, OTP ì¸ì¦, TrainingPlan |

### base.py (í•µì‹¬ í”„ë ˆì„ì›Œí¬)

**êµ¬ì¡°**:
- Part 1: RAG Workflow (lines 93-382)
  - `generate_sql()`, `extract_sql()`, Intermediate SQL
- Part 2: Abstraction (lines 383-693)
  - Abstract methods, Prompt generation, Token budget
- Part 3: Database (lines 761-1682)
  - 11ê°œ DB ì—°ê²°, Dynamic function binding, Closure
- Part 4: High-level API (lines 1683-2118)
  - `ask()`, `train()`, Training Plan, Visualization

**í•µì‹¬ ë©”ì„œë“œ**:
```python
def ask(question, print_results=True, auto_train=True, visualize=True):
    """All-in-one API: SQL ìƒì„± â†’ ì‹¤í–‰ â†’ í•™ìŠµ â†’ ì‹œê°í™”"""
    sql = self.generate_sql(question)
    df = self.run_sql(sql)
    if auto_train:
        self.add_question_sql(question, sql)
    if visualize:
        fig = self.get_plotly_figure(...)
    return sql, df, fig
```

### chromadb_vector.py (Vector Store)

**í•µì‹¬ ì„¤ê³„**:
- 3ê°œ Collection ë¶„ë¦¬ (SQL/DDL/Documentation)
- Deterministic UUID (ì¤‘ë³µ ë°©ì§€)
- Persistent vs In-memory ëª¨ë“œ

```python
def add_ddl(self, ddl: str) -> str:
    id = deterministic_uuid(ddl) + "-ddl"
    self.ddl_collection.add(documents=ddl, ids=id)
    return id
```

### openai_chat.py (LLM)

**í•µì‹¬ ì„¤ê³„**:
- Client ì£¼ì… (í…ŒìŠ¤íŠ¸ ìš©ì´)
- ìë™ ëª¨ë¸ ì„ íƒ (3500 í† í° ê¸°ì¤€)
- Azure OpenAI í˜¸í™˜

```python
def submit_prompt(self, prompt, **kwargs) -> str:
    num_tokens = sum(len(m["content"]) / 4 for m in prompt)

    # ìë™ ëª¨ë¸ ì„ íƒ
    if num_tokens > 3500:
        model = "gpt-3.5-turbo-16k"
    else:
        model = "gpt-3.5-turbo"

    response = self.client.chat.completions.create(model=model, messages=prompt)
    return response.choices[0].message.content
```

### __init__.py (ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸)

**í•µì‹¬ ì„¤ê³„**:
- OTP ì¸ì¦ (Vanna.AI Cloud)
- TrainingPlan í´ë˜ìŠ¤
- 30ê°œ ì´ìƒ ë ˆê±°ì‹œ í•¨ìˆ˜ deprecated

```python
def get_api_key(email: str, otp_code=None) -> str:
    # 1. í™˜ê²½ ë³€ìˆ˜ ì²´í¬
    if os.environ.get("VANNA_API_KEY"):
        return os.environ["VANNA_API_KEY"]

    # 2. OTP ì „ì†¡
    __unauthenticated_rpc_call("send_otp", [UserEmail(email=email)])

    # 3. OTP ì…ë ¥
    otp_code = input("Check your email for the code and enter it here: ")

    # 4. API Key ë°œê¸‰
    key = __unauthenticated_rpc_call("verify_otp", [UserOTP(email=email, otp=otp_code)])
    return key["key"]
```

---

## ì‹¤ì „ í™œìš© ê°€ì´ë“œ

### 1. ê¸°ë³¸ ì‚¬ìš© (Local)

```python
from vanna.chromadb import ChromaDB_VectorStore
from vanna.openai import OpenAI_Chat

# Mixinìœ¼ë¡œ ì¡°í•©
class MyVanna(ChromaDB_VectorStore, OpenAI_Chat):
    def __init__(self, config=None):
        ChromaDB_VectorStore.__init__(self, config=config)
        OpenAI_Chat.__init__(self, config=config)

# ì´ˆê¸°í™”
vn = MyVanna(config={
    "api_key": "sk-...",  # OpenAI API Key
    "model": "gpt-3.5-turbo"
})

# DB ì—°ê²°
vn.connect_to_postgres(
    host="localhost",
    dbname="mydb",
    user="user",
    password="pass"
)

# í•™ìŠµ
vn.train(ddl="CREATE TABLE users (id INT, name TEXT, email TEXT)")
vn.train(
    question="ì „ì²´ ì‚¬ìš©ì ìˆ˜ëŠ”?",
    sql="SELECT COUNT(*) FROM users"
)

# SQL ìƒì„±
sql = vn.generate_sql("ì´ë©”ì¼ì´ gmailì¸ ì‚¬ìš©ìëŠ” ëª‡ ëª…?")
print(sql)
# SELECT COUNT(*) FROM users WHERE email LIKE '%@gmail.com'

# ì‹¤í–‰ + ì‹œê°í™”
sql, df, fig = vn.ask("ì›”ë³„ ê°€ì…ì ìˆ˜ ì¶”ì´ë¥¼ ì°¨íŠ¸ë¡œ ë³´ì—¬ì¤˜")
fig.show()  # Plotly ì°¨íŠ¸
```

### 2. Cloud ì‚¬ìš© (Vanna.AI)

```python
from vanna.remote import VannaDefault
import vanna as vn

# 1. API Key ë°œê¸‰ (ì²« ì‹¤í–‰ë§Œ)
api_key = vn.get_api_key(email="user@example.com")
# Check your email for the code and enter it here: 123456

# 2. Vanna ì´ˆê¸°í™”
vanna_instance = VannaDefault(
    model="my-sales-model",
    api_key=api_key
)

# 3. ì´í›„ ë™ì¼
vanna_instance.connect_to_postgres(...)
vanna_instance.train(...)
sql = vanna_instance.generate_sql("...")
```

### 3. Training Planìœ¼ë¡œ ëŒ€ëŸ‰ í•™ìŠµ

```python
# 1. Training Plan ìƒì„±
plan = vn.get_training_plan_postgres(
    filter_schemas=["public"],
    use_historical_queries=True  # pg_stat_statementsì—ì„œ ê³¼ê±° ì¿¼ë¦¬ ê°€ì ¸ì˜¤ê¸°
)

# 2. Preview
for item in plan.get_summary():
    print(item)

# Output:
# Train on DDL: public users
# Train on DDL: public orders
# Train on DDL: public temp_table
# Train on SQL: SELECT * FROM users WHERE ...

# 3. í•„í„°ë§
plan.remove_item("Train on DDL: public temp_table")

# 4. ì‹¤í–‰
vn.train(plan=plan)
```

### 4. Custom LLM êµ¬í˜„

```python
from vanna.base import VannaBase
from vanna.chromadb import ChromaDB_VectorStore

class Anthropic_Chat(VannaBase):
    def __init__(self, config=None):
        VannaBase.__init__(self, config=config)
        from anthropic import Anthropic
        self.client = Anthropic(api_key=config["api_key"])

    def submit_prompt(self, prompt, **kwargs) -> str:
        # Claude API í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        system = next(m["content"] for m in prompt if m["role"] == "system")
        messages = [m for m in prompt if m["role"] != "system"]

        response = self.client.messages.create(
            model="claude-3-sonnet-20240229",
            system=system,
            messages=messages,
            max_tokens=1024
        )
        return response.content[0].text

    def system_message(self, message: str) -> dict:
        return {"role": "system", "content": message}

    def user_message(self, message: str) -> dict:
        return {"role": "user", "content": message}

    def assistant_message(self, message: str) -> dict:
        return {"role": "assistant", "content": message}

# ì‚¬ìš©
class MyVanna(ChromaDB_VectorStore, Anthropic_Chat):
    def __init__(self, config=None):
        ChromaDB_VectorStore.__init__(self, config=config)
        Anthropic_Chat.__init__(self, config=config)

vn = MyVanna(config={"api_key": "sk-ant-..."})
```

### 5. Production ì„¤ì •

```python
from vanna.chromadb import ChromaDB_VectorStore
from vanna.openai import OpenAI_Chat
from openai import OpenAI
import os

class MyVanna(ChromaDB_VectorStore, OpenAI_Chat):
    def __init__(self, config=None):
        ChromaDB_VectorStore.__init__(self, config=config)
        OpenAI_Chat.__init__(self, config=config)

# Client ì£¼ì… (íƒ€ì„ì•„ì›ƒ, ë¦¬íŠ¸ë¼ì´ ì„¤ì •)
client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    timeout=30.0,
    max_retries=3
)

vn = MyVanna(
    client=client,
    config={
        "model": "gpt-3.5-turbo",
        "temperature": 0.0,  # ê²°ì •ì  ì¶œë ¥
        # ChromaDB persistent mode
        "path": "./chroma_db",
        "client_settings": {
            "anonymized_telemetry": False
        }
    }
)

# DB ì—°ê²° (Connection Pool ì‚¬ìš©)
from sqlalchemy import create_engine
engine = create_engine(
    f"postgresql://{user}:{password}@{host}:{port}/{dbname}",
    pool_size=10,
    max_overflow=20
)

vn.run_sql = lambda sql: pd.read_sql(sql, engine)

# ì—ëŸ¬ í•¸ë“¤ë§
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=4, max=60)
)
def generate_sql_with_retry(question):
    return vn.generate_sql(question)

# ì‚¬ìš©
try:
    sql = generate_sql_with_retry("ì§€ë‚œë‹¬ ë§¤ì¶œì€?")
except Exception as e:
    logging.error(f"Failed to generate SQL: {e}")
    # Fallback ì²˜ë¦¬
```

---

## ìŠ¤ì¼€ì¼ë³„ ì „ëµ

### Small Scale (< 10 í…Œì´ë¸”, < 100 req/day)

**íŠ¹ì§•**:
- ê°œë°œ í™˜ê²½ ë˜ëŠ” PoC
- Training Plan ë¶ˆí•„ìš”
- In-memory Vector Store ê°€ëŠ¥

**ê¶Œì¥ ì„¤ì •**:
```python
vn = MyVanna(config={
    "api_key": "sk-...",
    "model": "gpt-3.5-turbo",
    # In-memory ChromaDB
    "client": chromadb.Client()
})

# ìˆ˜ë™ í•™ìŠµ (10ê°œ ì´í•˜)
vn.train(ddl="CREATE TABLE users (...)")
vn.train(ddl="CREATE TABLE orders (...)")
```

**ë¹„ìš©**: $10-50/month

---

### Medium Scale (10-100 í…Œì´ë¸”, 100-1K req/day)

**íŠ¹ì§•**:
- í”„ë¡œë•ì…˜ ì´ˆê¸°
- Training Plan í•„ìˆ˜
- Persistent Vector Store

**ê¶Œì¥ ì„¤ì •**:
```python
# Persistent ChromaDB
vn = MyVanna(config={
    "api_key": "sk-...",
    "model": "gpt-3.5-turbo",
    "path": "./chroma_db"  # Persistent
})

# Training Planìœ¼ë¡œ ëŒ€ëŸ‰ í•™ìŠµ
plan = vn.get_training_plan_postgres(filter_schemas=["public"])
plan.remove_item("Train on DDL: public temp_table")
vn.train(plan=plan)

# Rate Limit ëŒ€ì‘
from tenacity import retry
@retry(stop=stop_after_attempt(3))
def generate_sql_with_retry(question):
    return vn.generate_sql(question)
```

**ë¹„ìš©**: $50-500/month

**ìµœì í™”**:
- ìë™ ëª¨ë¸ ì„ íƒ í™œìš© (gpt-3.5-turbo vs 16k)
- ìºì‹± ë ˆì´ì–´ ì¶”ê°€ (Redis)

---

### Large Scale (100+ í…Œì´ë¸”, 1K+ req/day)

**íŠ¹ì§•**:
- ëŒ€ê·œëª¨ ì—”í„°í”„ë¼ì´ì¦ˆ
- Domainë³„ ëª¨ë¸ ë¶„ë¦¬
- ë¹„ìš© ìµœì í™” í•„ìˆ˜

**ê¶Œì¥ ì„¤ì •**:

#### 1. Domainë³„ ëª¨ë¸ ë¶„ë¦¬
```python
# Sales ëª¨ë¸
vn_sales = MyVanna(config={..., "path": "./chroma_db_sales"})
plan_sales = vn_sales.get_training_plan_postgres(filter_schemas=["sales"])
vn_sales.train(plan=plan_sales)

# Analytics ëª¨ë¸
vn_analytics = MyVanna(config={..., "path": "./chroma_db_analytics"})
plan_analytics = vn_analytics.get_training_plan_postgres(filter_schemas=["analytics"])
vn_analytics.train(plan=plan_analytics)
```

**ì¥ì **:
- ë„ë©”ì¸ë³„ ì •í™•ë„ í–¥ìƒ (20-30%)
- ê²€ìƒ‰ ì†ë„ ì¦ê°€ (ì‘ì€ Vector Store)
- ê¶Œí•œ ë¶„ë¦¬

#### 2. Tier-based ëª¨ë¸ ì„ íƒ
```python
class SmartVanna(MyVanna):
    def generate_sql(self, question, **kwargs):
        complexity = self.estimate_complexity(question)

        if complexity == "simple":
            kwargs["model"] = "gpt-3.5-turbo"  # ì €ë ´
        elif complexity == "complex":
            kwargs["model"] = "gpt-4"  # ë¹„ì‹¸ì§€ë§Œ ì •í™•

        return super().generate_sql(question, **kwargs)

    def estimate_complexity(self, question):
        # JOIN, ì„œë¸Œì¿¼ë¦¬, ì§‘ê³„ í•¨ìˆ˜ ë“±ìœ¼ë¡œ íŒë‹¨
        if any(keyword in question.lower() for keyword in ["join", "subquery", "aggregate"]):
            return "complex"
        return "simple"
```

**ë¹„ìš© ì ˆê°**: 30-50%

#### 3. ìºì‹± ë ˆì´ì–´
```python
import hashlib
import redis

redis_client = redis.Redis(host='localhost', port=6379)

def generate_sql_cached(question):
    cache_key = hashlib.md5(question.encode()).hexdigest()
    cached = redis_client.get(cache_key)

    if cached:
        return cached.decode()

    sql = vn.generate_sql(question)
    redis_client.setex(cache_key, 3600, sql)  # 1ì‹œê°„ ìºì‹œ
    return sql
```

**ìºì‹œ Hit Rate**: 20-40% â†’ ë¹„ìš© 20-40% ì ˆê°

#### 4. ëª¨ë‹ˆí„°ë§ (Prometheus + Grafana)
```python
from prometheus_client import Counter, Histogram

token_counter = Counter('vanna_tokens_total', 'Total tokens used', ['model'])
latency_histogram = Histogram('vanna_latency_seconds', 'Request latency')

class MonitoredVanna(MyVanna):
    def submit_prompt(self, prompt, **kwargs):
        with latency_histogram.time():
            response = super().submit_prompt(prompt, **kwargs)

        num_tokens = sum(len(m["content"]) / 4 for m in prompt)
        model = kwargs.get("model", "gpt-3.5-turbo")
        token_counter.labels(model=model).inc(num_tokens)

        return response
```

**ë¹„ìš©**: $500+/month

---

## í•µì‹¬ íŒ¨í„´ ìš”ì•½

### 1. Mixin íŒ¨í„´ (êµ¬ì¡°ì  íŒ¨í„´)

**ëª©ì **: ì—¬ëŸ¬ ê¸°ëŠ¥ì„ ë…ë¦½ì ìœ¼ë¡œ ì¡°í•©

**êµ¬í˜„**:
```python
class VannaBase(ABC):
    @abstractmethod
    def abstract_method(self): pass

class FeatureA(VannaBase):
    def abstract_method(self): return "A"

class FeatureB(VannaBase):
    def another_method(self): return "B"

class Combined(FeatureA, FeatureB):
    pass  # ë‘ Mixinì„ ì¡°í•©
```

**ì ìš©**:
- Vector Store + LLM ì¡°í•©
- ìƒˆ êµ¬í˜„ ì¶”ê°€ ì‹œ base ìˆ˜ì • ë¶ˆí•„ìš”

---

### 2. RAG Pipeline (ì•„í‚¤í…ì²˜ íŒ¨í„´)

**ëª©ì **: Fine-tuning ì—†ì´ ë†’ì€ ì •í™•ë„

**íë¦„**:
```
ì§ˆë¬¸ â†’ Retrieval (Vector Search) â†’ Augmentation (Prompt êµ¬ì„±) â†’ Generation (LLM) â†’ SQL
```

**ì ìš©**:
- ChromaDBë¡œ ìœ ì‚¬ SQL/DDL ê²€ìƒ‰
- Few-shot learning (ê³¼ê±° ì˜ˆì‹œ í™œìš©)

---

### 3. Dynamic Function Binding (Closure íŒ¨í„´)

**ëª©ì **: DB ë…ë¦½ì„±

**êµ¬í˜„**:
```python
def connect_to_db():
    conn = psycopg2.connect(...)
    return conn

def run_sql(sql):
    conn = connect_to_db()  # Closure!
    ...

self.run_sql = run_sql  # ëŸ°íƒ€ì„ ë°”ì¸ë”©
```

**ì ìš©**:
- 11ê°œ DB ì§€ì›
- Connection pool ìº¡ìŠí™”

---

### 4. Token Budget ê´€ë¦¬ (ì œì•½ ì¡°ê±´ íŒ¨í„´)

**ëª©ì **: LLM ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ ëŒ€ì‘

**êµ¬í˜„**:
```python
current_tokens = count_tokens(prompt)
for item in items:
    if current_tokens + count_tokens(item) < max_tokens:
        prompt += item
    else:
        break
```

**ì ìš©**:
- 14K í† í° budget
- ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì¶”ê°€

---

### 5. Template Method (í–‰ë™ íŒ¨í„´)

**ëª©ì **: ê³µí†µ ì•Œê³ ë¦¬ì¦˜ + êµ¬í˜„ ìœ„ì„

**êµ¬í˜„**:
```python
class VannaBase:
    def generate_sql(self, question):
        # 1. Retrieval (êµ¬í˜„ ìœ„ì„)
        examples = self.get_similar_question_sql(question)  # Abstract

        # 2. Augmentation (ê³µí†µ ë¡œì§)
        prompt = self.build_prompt(question, examples)

        # 3. Generation (êµ¬í˜„ ìœ„ì„)
        response = self.submit_prompt(prompt)  # Abstract

        return self.extract_sql(response)
```

**ì ìš©**:
- `generate_sql()` ì „ì²´ íë¦„
- ê° ë‹¨ê³„ëŠ” abstract methodë¡œ ìœ„ì„

---

### 6. Pipeline íŒ¨í„´ (í†µí•© íŒ¨í„´)

**ëª©ì **: ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ë‹¨ì¼ APIë¡œ í†µí•©

**êµ¬í˜„**:
```python
def ask(self, question):
    # 1. Generate SQL
    sql = self.generate_sql(question)

    # 2. Execute
    df = self.run_sql(sql)

    # 3. Auto-train (optional)
    if auto_train:
        self.add_question_sql(question, sql)

    # 4. Visualize (optional)
    if visualize:
        fig = self.generate_plotly_figure(question, df)

    return sql, df, fig
```

**ì ìš©**:
- `ask()` - 6ë‹¨ê³„ í†µí•©
- ì‚¬ìš©ìëŠ” í•œ ì¤„ë¡œ ëª¨ë“  ê¸°ëŠ¥ ì‚¬ìš©

---

### 7. Preview-Modify-Execute (ì‚¬ìš©ì ì œì–´ íŒ¨í„´)

**ëª©ì **: ìë™í™” + ì‚¬ìš©ì ì œì–´

**êµ¬í˜„**:
```python
# 1. Preview
plan = create_plan()
print(plan.summary())

# 2. Modify
plan.remove_item("unwanted")

# 3. Execute
execute(plan)
```

**ì ìš©**:
- TrainingPlan
- ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì „ í™•ì¸ ê°€ëŠ¥

---

## í”„ë¡œì íŠ¸ì—ì„œ ë°°ìš´ í•µì‹¬ êµí›ˆ

### 1. ì¶”ìƒí™”ì˜ í˜ (Mixin íŒ¨í„´)

**êµí›ˆ**: ê¸°ëŠ¥ì„ ë…ë¦½ì ì¸ Mixinìœ¼ë¡œ ë¶„ë¦¬í•˜ë©´ ì¡°í•©ì˜ ìœ ì—°ì„±ì´ ê·¹ëŒ€í™”ë©ë‹ˆë‹¤.

**ì ìš©**:
- Vector Storeì™€ LLMì„ ì™„ì „íˆ ë…ë¦½ì ìœ¼ë¡œ êµ¬í˜„
- ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì¡°í•© ì„ íƒ ê°€ëŠ¥
- ìƒˆ êµ¬í˜„ ì¶”ê°€ ì‹œ ê¸°ì¡´ ì½”ë“œ ìˆ˜ì • ë¶ˆí•„ìš”

**ë‹¤ë¥¸ í”„ë¡œì íŠ¸ì— ì ìš©**:
```python
# ì˜ˆ: Web Framework
class RequestHandler(ABC): ...
class JSONSerializer(RequestHandler): ...
class XMLSerializer(RequestHandler): ...
class BasicAuth(RequestHandler): ...
class JWTAuth(RequestHandler): ...

# ì¡°í•©
class MyAPI(JSONSerializer, JWTAuth):
    pass

class LegacyAPI(XMLSerializer, BasicAuth):
    pass
```

---

### 2. RAG vs Fine-tuning ì„ íƒ

**êµí›ˆ**: ë¹ ë¥´ê²Œ ë³€í•˜ëŠ” ë°ì´í„°ëŠ” RAGê°€ ìœ ë¦¬í•©ë‹ˆë‹¤.

**RAG ì„ íƒ ì¡°ê±´**:
- âœ… ë°ì´í„°ê°€ ìì£¼ ë³€ê²½ (DB ìŠ¤í‚¤ë§ˆ)
- âœ… ì¦‰ì‹œ ì—…ë°ì´íŠ¸ í•„ìš”
- âœ… ë¹„ìš© ë¯¼ê°

**Fine-tuning ì„ íƒ ì¡°ê±´**:
- âœ… ë°ì´í„°ê°€ ê³ ì •ì  (ë„ë©”ì¸ ì§€ì‹)
- âœ… ì´ˆì €ì§€ì—° í•„ìš”
- âœ… ì˜¤í”„ë¼ì¸ ì‚¬ìš©

**Vannaì˜ ì„ íƒ**: RAG (DB ìŠ¤í‚¤ë§ˆëŠ” ìì£¼ ë³€ê²½ë¨)

---

### 3. Dynamic Function Bindingì˜ íŠ¸ë ˆì´ë“œì˜¤í”„

**ì¥ì **:
- ì½”ë“œ ê°„ê²° (11ê°œ DB â†’ 11ê°œ í•¨ìˆ˜ë§Œ)
- Closureë¡œ connection ìº¡ìŠí™”

**ë‹¨ì **:
- IDE ìë™ì™„ì„± ì–´ë ¤ì›€
- ëŸ°íƒ€ì„ ì—ëŸ¬ ê°€ëŠ¥ì„±

**êµí›ˆ**: ì½”ë“œ ê°„ê²°ì„± vs íƒ€ì… ì•ˆì •ì„± íŠ¸ë ˆì´ë“œì˜¤í”„

**ê°œì„  ë°©ë²•**:
```python
# Type hintë¡œ ëª…ì‹œ
def connect_to_postgres(self, ...):
    def run_sql_postgres(sql: str) -> pd.DataFrame: ...

    self.run_sql: Callable[[str], pd.DataFrame] = run_sql_postgres
    self.run_sql_is_set = True
```

---

### 4. Token Budgetì˜ í˜„ì‹¤ì  ì œì•½

**êµí›ˆ**: LLMì€ ë¬´í•œí•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê°€ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤. ìš°ì„ ìˆœìœ„ê°€ í•„ìš”í•©ë‹ˆë‹¤.

**Vannaì˜ ìš°ì„ ìˆœìœ„**:
1. System prompt (í•­ìƒ)
2. Few-shot examples (ê°€ì¥ ì¤‘ìš”)
3. DDL (ê°€ëŠ¥í•œ ë§Œí¼)
4. Documentation (ì—¬ìœ  ìˆìœ¼ë©´)

**ë‹¤ë¥¸ í”„ë¡œì íŠ¸ì— ì ìš©**:
- ë¬¸ì„œ ê²€ìƒ‰: ê°€ì¥ ê´€ë ¨ ë†’ì€ ì²­í¬ë§Œ
- ì½”ë“œ ë¦¬ë·°: ë³€ê²½ëœ íŒŒì¼ ìš°ì„ 
- ë²ˆì—­: í•µì‹¬ ë¬¸ì¥ ìš°ì„ 

---

### 5. Breaking Changeì˜ ì˜¬ë°”ë¥¸ ë°©ë²•

**êµí›ˆ**: Deprecationì€ ëª…í™•í•˜ê³  ê³¼ê°í•˜ê²Œ.

**Vannaì˜ ì „ëµ**:
- ì¦‰ì‹œ ì—ëŸ¬ (Warning ì•„ë‹˜)
- ëª…í™•í•œ ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ
- ì½”ë“œ ì˜ˆì‹œ í¬í•¨

**íš¨ê³¼**:
- ì‚¬ìš©ìê°€ ì¦‰ì‹œ ë§ˆì´ê·¸ë ˆì´ì…˜
- ê¸°ìˆ  ë¶€ì±„ ë¹ ë¥´ê²Œ ì œê±°
- ì½”ë“œë² ì´ìŠ¤ ì •ë¦¬

**ë‹¤ë¥¸ í”„ë¡œì íŠ¸ì— ì ìš©**:
- API ë²„ì „ ë³€ê²½
- ì„¤ì • íŒŒì¼ í˜•ì‹ ë³€ê²½
- ë°ì´í„° ëª¨ë¸ ë³€ê²½

---

### 6. Preview-Modify-Execute íŒ¨í„´

**êµí›ˆ**: ìë™í™”ì™€ ì‚¬ìš©ì ì œì–´ì˜ ê· í˜•.

**ì ìš© ì‚¬ë¡€**:
- Training Plan (DB ìŠ¤ìº”)
- Bulk email (ìˆ˜ì‹ ì í™•ì¸)
- File deletion (ì‚­ì œ ëª©ë¡ í™•ì¸)
- Database migration (ë³€ê²½ ì‚¬í•­ í™•ì¸)

**í•µì‹¬ ì›ì¹™**:
- ìë™í™” (ìŠ¤ìº”/ìƒì„±)
- íˆ¬ëª…ì„± (preview)
- ì œì–´ (modify)
- ì•ˆì „ì„± (execute ì „ í™•ì¸)

---

### 7. Closureë¡œ State ìº¡ìŠí™”

**êµí›ˆ**: ClosureëŠ” Connection pool ë“± state ìº¡ìŠí™”ì— ìœ ìš©í•©ë‹ˆë‹¤.

**Vannaì˜ ì‚¬ìš©**:
```python
def connect_to_postgres(self, host, dbname, user, password):
    def connect_to_db():
        return psycopg2.connect(host=host, dbname=dbname, ...)

    def run_sql(sql):
        conn = connect_to_db()  # Closure!
        ...

    self.run_sql = run_sql
```

**ì¥ì **:
- Connection ì •ë³´ ìº¡ìŠí™”
- ì‚¬ìš©ìëŠ” connection ê´€ë¦¬ ë¶ˆí•„ìš”
- í•¨ìˆ˜ë§Œ í˜¸ì¶œí•˜ë©´ ë¨

**ë‹¤ë¥¸ í”„ë¡œì íŠ¸ì— ì ìš©**:
- API client (token ìº¡ìŠí™”)
- File handler (file path ìº¡ìŠí™”)
- Cache (cache key ìº¡ìŠí™”)

---

## ìµœì¢… ìš”ì•½

**VannaëŠ” ë¬´ì—‡ì¸ê°€?**
- Text-to-SQL RAG í”„ë ˆì„ì›Œí¬
- Mixin íŒ¨í„´ìœ¼ë¡œ Vector Store + LLM ì¡°í•©
- 11ê°œ DB ì§€ì›, Plotly ì°¨íŠ¸ ìë™ ìƒì„±

**í•µì‹¬ ì„¤ê³„ ê²°ì •**:
1. **Mixin íŒ¨í„´**: Vector Storeì™€ LLM ë…ë¦½
2. **RAG**: Fine-tuning ë¶ˆí•„ìš”, ì¦‰ì‹œ ì—…ë°ì´íŠ¸
3. **Dynamic Binding**: 11ê°œ DB ë‹¨ì¼ ì¸í„°í˜ì´ìŠ¤
4. **Token Budget**: 14K ì œí•œ ë‚´ ìš°ì„ ìˆœìœ„ ê´€ë¦¬
5. **Training Plan**: Preview-Modify-Execute
6. **Breaking Change**: ëª…í™•í•œ ë§ˆì´ê·¸ë ˆì´ì…˜ ê°•ì œ

**í”„ë¡œì íŠ¸ êµ¬ì¡°**:
- `base.py` (2118ì¤„) - í•µì‹¬ í”„ë ˆì„ì›Œí¬
- `chromadb_vector.py` (257ì¤„) - Vector Store
- `openai_chat.py` (128ì¤„) - LLM
- `__init__.py` (399ì¤„) - ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸

**ë°°ìš´ í•µì‹¬ êµí›ˆ**:
1. Mixin íŒ¨í„´ì˜ ì¡°í•© ìœ ì—°ì„±
2. RAG vs Fine-tuning ì„ íƒ ê¸°ì¤€
3. Token Budgetì˜ í˜„ì‹¤ì  ì œì•½
4. Breaking Changeì˜ ê³¼ê°í•¨
5. Preview-Modify-Execute íŒ¨í„´
6. Closureë¡œ State ìº¡ìŠí™”

**ì ìš© ê°€ëŠ¥í•œ ë„ë©”ì¸**:
- Text-to-Code (Python, JS, SQL ë“±)
- Document QA (RAG)
- API Client Framework (Mixin)
- Database Toolkit (Dynamic Binding)

**í•œ ì¤„ ìš”ì•½**: VannaëŠ” Mixin íŒ¨í„´ê³¼ RAGë¥¼ í™œìš©í•˜ì—¬ Vector Storeì™€ LLMì„ ììœ ë¡­ê²Œ ì¡°í•©í•˜ëŠ” Text-to-SQL í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
